import sys
import os
import logging
from snakemake.io import glob_wildcards, expand
import csv
import pandas as pd
import numpy as np

logging.basicConfig(
    filename="output.log", level=logging.DEBUG, filemode='w')

inputdir="BAM_FILES"
samplelist = []
discarded = []
size = 10000
target_file="targets.bed"
fish_file="Samples_Barcodes_purity_CEP.txt"
fish_info =  pd.read_csv(fish_file, sep='\t', header=(0))
annotation="hg19.refFlat.txt"
#https://pages.charlesreid1.com/how-do-i-snakemake/converting/

#condactivate pypette-dna
#run in a node with snakemake -rj 10
"""
# consider for the pipeline only bam files bigger than size
# put the filenames of the bam files (without extension) in a list
# convert the list to string
#divide in 2 groups tumor and normal

#run with snakemake --cluster qsub -j 10

"""

for file in os.listdir(inputdir):
    full_path = os.path.join(inputdir, file)
    filesize=os.path.getsize(full_path)
    if file.endswith('.bam') and filesize > size:
        samplelist.append(file.split(".")[0])
        logging.debug("good file: %s, size: %d ",file, filesize)
    elif file.endswith('.bam') and filesize < size:
        discarded.append(file.split(".")[0])
        logging.debug("bad file: %s, size: %d",file, filesize)
logging.debug("samplelist: %s,length: %d",samplelist,len(samplelist))
logging.debug("discarded: %s, length: %d",discarded,len(discarded))


T = [x for x in samplelist if '1TA' in x]
TUMOR = ' '.join(map(str, T))
logging.debug("TUMOR: %s",TUMOR)
logging.debug("N TUMORS: %d", len(T))
N = [x for x in samplelist if '2NAD' in x]
NORMAL = ' '.join(map(str, N))
logging.debug("NORMAL: %s",NORMAL)
logging.debug("N NORMALS: %d", len(N))


#insert RATIO_gene_CEN7 (Met absolute value/CEN7) column in the FISH table
mask = (fish_info['CEN7'] != "UNK")
z_valid = fish_info[mask]
fish_info['RATIO_gene_CEN7'] = "UNK"
#make CEN7 float
z_valid['CEN7'] = z_valid['CEN7'].apply(lambda x: float(x))
#make NewMet float
z_valid['NewMet'].apply(lambda x: float(x))
fish_info.loc[mask, 'RATIO_gene_CEN7'] = round(((z_valid['NewMet']) / (z_valid['CEN7'])),2)
#print(fish_info)

"""

# execute only on a subset of the dataset (2Tumors and 2Normals)

T_2samples = T[0:2]
N_2samples = N[0:2]

TUMOR = ' '.join(map(str, T_2samples))
logging.debug("TUMOR sub: %s", TUMOR)
logging.debug("N TUMORS sub: %d", len(T_2samples))

NORMAL = ' '.join(map(str, N_2samples))
logging.debug("NORMAL sub: %s", NORMAL)
logging.debug("N NORMALS sub: %d", len(N_2samples))
"""


# ignore errors
shell.prefix("set +o pipefail; ")

"""So far, we always executed the workflow by specifying a target file at the
command line. Apart from filenames, Snakemake also accepts rule names as
targets if the referred rule does not have wildcards. Hence, it is possible
to write target rules collecting particular subsets of the desired results or
all results. Moreover, if no target is given at the command line,
Snakemake will define the first rule of the Snakefile as the target.
Hence, it is best practice to have a rule all at the top of the workflow
which has all typically desired target files as input files.

Define in "rule all" all the ouput files you want to obtain.
The intermediate files necessary to obtain these output files will be
automatically generated.
"""
rule all:
    input:
        #"gene_summary.tsv",
        "gene_summary_new_chr7.tsv",
        expand('CNVKIT_PLOTS/{tumor}-scatter-region.pdf', tumor=TUMOR.split(' ')),
        expand('CNVKIT_PLOTS/all_heatmap.pdf', tumor=TUMOR.split(' '))

        #expand('{tumor}.CNVKIT/{tumor}.call.num_genes.cns', tumor=TUMOR.split(' '))

"""Targeted Amplicon Sequencing with cnvkit (TAS)

WITH ANNOTATION FILE Flagstat.txt

When amplicon sequencing is used as a targeted capture method, no off-target
reads are sequenced. While this limits the copy number information available in
the sequencing data versus hybrid capture, CNVkit can analyze TAS data using
only on-target coverages and excluding all off-target regions from the analysis.
This approach does not collect any copy number information between targeted
regions, so it should only be used if you have in fact prepared your samples
with a targeted amplicon sequencing protocol. It also does not attempt to
further normalize each amplicon at the gene level, though this may be addressed
in a future version of CNVkit.


IMPORTANT: Do not mark duplicates in the BAM files for samples sequenced by
this method.

"""


"""
step1) Format the targets

            Parameters
            -------

            interval : BED or interval file listing the targeted regions.
             --split   Split large tiled intervals into smaller, consecutive
                       targets.

"""


rule cnvkit_target:
    input:
        target_file
    output:
        "CNVKIT_DATA/targets.split.bed"
    params:
        annotation
    shell:
        "cnvkit.py target {input} --annotate {params} --split -o {output}"


rule cnvkit_antitarget:
    output:
        "CNVKIT_DATA/antitarget.cnn"
    shell:
        "touch {output}"



"""step3.2) Calculate coverage in the given regions from BAM read depths - NORMAL

            Parameters
            -------
            bam_file : Normal Mapped sequence reads (.bam)
            interval : Intervals (.bed or .list)


            Returns
            -------
            for each NORMAL sample the coverage (.cnn)

"""


rule cnvkit_coverage_normal:
    input:
        BAM_NORMAL=os.path.join(inputdir, "{normal}.bam"),
        TARGET="CNVKIT_DATA/targets.split.bed"
    output:
        "CNVKIT_DATA/{normal}.targetcoverage.cnn"
    shell:
        "cnvkit.py coverage {input.BAM_NORMAL} {input.TARGET} -p 12 -o {output}"


rule cnvkit_coverage_tumor:
    input:
        BAM_TUMOR=os.path.join(inputdir, "{tumor}.bam"),
        TARGET="CNVKIT_DATA/targets.split.bed"
    output:
        "{tumor}.CNVKIT/{tumor}.targetcoverage.cnn"
    shell:
        "cnvkit.py coverage {input.BAM_TUMOR} {input.TARGET} -p 12 -o {output}"

#not included
rule cnvkit_anti_target_coverage_tumor:
    input:
        BAM_TUMOR=os.path.join(inputdir, "{tumor}.bam"),
        TARGET="CNVKIT_DATA/antitarget.cnn"
    output:
        "{tumor}.CNVKIT/{tumor}.antitargetcoverage.cnn"
    shell:
        "cnvkit.py coverage -p 10 {input.BAM_TUMOR} {input.TARGET} -p 12 -o {output}"




"""step4) Build a reference from normal samples

        Parameters
        -------

        references : List of normal-sample target or antitarget .cnn files, or the
            directory that contains them. (We want use normal-samples)

        Returns
        -------
        reference from normal samples

"""

rule cnvkit_reference:
    input:
        REFERENCES=expand(["CNVKIT_DATA/{normal}.targetcoverage.cnn"], normal=NORMAL.split(' '))
    output:
        "CNVKIT_DATA/reference.cnn",
    shell:
        "cnvkit.py reference {input.REFERENCES} -o {output}"



#snakemake CNVKIT_DATA/reference.cnn





"""STRATEGY 1.2 for TAS:

!!! you should build the reference as described below in 3.2 and 4 !!!

The batch -m amplicon option uses the given targets to infer coverage

        Parameters
        -------
        input:
        bam_files : Mapped sequence tumor reads (.bam).
        targets : BED or interval file listing the targeted regions.
        normal reference : reference built from normal samples (.cnn).

        Returns
        -------
        A folder containing all CNV data

#this rule accepts only some methods like amplicon. But not hmm-tumor


rule cnvkit_batch:
    input:
        BAM_TUMOR=os.path.join(inputdir, "{tumor}.bam"),
        REFERENCE="CNVKIT_DATA/reference.cnn"
    output:
        "{tumor}.CNVKIT/reference.target-tmp.bed",
        "{tumor}.CNVKIT/reference.antitarget-tmp.bed",
        "{tumor}.CNVKIT/{tumor}.targetcoverage.cnn",
        "{tumor}.CNVKIT/{tumor}.cns",
        "{tumor}.CNVKIT/{tumor}.cnr",
        "{tumor}.CNVKIT/{tumor}.antitargetcoverage.cnn"
    params:
        FOLDER="{tumor}.CNVKIT"
    shell:
        "cnvkit.py batch -m amplicon -p 10 -r {input.REFERENCE} --output-dir {params.FOLDER} {input.BAM_TUMOR}"


"""

rule cnvkit_fix:
    input:
        TARGET_COVERAGE="{tumor}.CNVKIT/{tumor}.targetcoverage.cnn",
        ANTITARGET="{tumor}.CNVKIT/{tumor}.antitargetcoverage.cnn",
        REFERENCE_NORMALS="CNVKIT_DATA/reference.cnn"
    output:
        "{tumor}.CNVKIT/{tumor}.cnr"
    shell:
        "cnvkit.py fix {input.TARGET_COVERAGE} {input.ANTITARGET} {input.REFERENCE_NORMALS} --no-edge -o {output}"



rule cnvkit_segment:
    input:
        "{tumor}.CNVKIT/{tumor}.cnr"
    output:
        "{tumor}.CNVKIT/{tumor}.cns"
    shell:
        "cnvkit.py segment -m hmm-tumor {input} -o {output}"

"""
cnvkit_call not taking into account ploidy
"""
"""
rule cnvkit_call:
    input:
        "{tumor}.CNVKIT/{tumor}.cns"
    output:
        "{tumor}.CNVKIT/{tumor}.call.cns"
    shell:
        "cnvkit.py call {input} -o {output}"
"""



"""
cnvkit_call taking into account ploidy
"""

rule cnvkit_call:
    input:
        "{tumor}.CNVKIT/{tumor}.cns",
    output:
        "{tumor}.CNVKIT/{tumor}.call.cns"
    message:
        "Taking into account ploidy.."
    params:
        FISH=fish_info

    run:
       import pandas as pd
       PL=(params.FISH.loc[params.FISH['Tumor_Sample_Barcode'] == wildcards.tumor, 'Ploidy'].to_numpy())
       if PL:
           print(wildcards.tumor)
           print(PL,"PL")
           PLO=(PL[0])
           if PLO!= "UNK":
               subprocess.call(['bash','./script3.sh',str(PLO),str(output),str(input)])
           else:
               print(PL, "plounk")
               subprocess.call(['bash','./script4.sh',str(output),str(input)])
       else:
           print(PL, "notplo", input)
           subprocess.call(['bash','./script4.sh',str(output),str(input)])



rule cnvkit_chr7:
    input:
       TAS_data= "{tumor}.CNVKIT/{tumor}.cnr"
    output:
        "{tumor}.CNVKIT/{tumor}_chr7.cnr"
    run:
        import pandas as pd
        TAS=pd.read_csv(input.TAS_data, sep='\t', header=(0))
        poscn = TAS[TAS.chromosome == "chr7"]
        l2mean=poscn["log2"].mean()
        poscn["log2_chr7"]=l2mean
        dmean=poscn["depth"].mean()
        poscn["depth_chr7"]=dmean
        wmean=poscn["weight"].mean()
        poscn["weight_chr7"]=wmean
        minstart=poscn["start"].min()
        poscn["start_chr7"]=minstart
        maxend=poscn["end"].max()
        poscn["end_chr7"]=maxend
        poscn['region'] = "chr7"
        poscn_c7 = poscn[["region","start_chr7","end_chr7","depth_chr7","log2_chr7","weight_chr7"]].copy()
        df = poscn_c7.drop_duplicates()
        df['id'] = wildcards.tumor
        df.to_csv(output[0], sep='\t', index=False)







"""
count genes in cns
"""
rule count_genes_in_cns:
    input:
        TAS_data="{tumor}.CNVKIT/{tumor}.call.cns"
    output:
        "{tumor}.CNVKIT/{tumor}.call.num_genes.cns"
    run:
        import pandas as pd
        TAS=pd.read_csv(input.TAS_data, sep='\t', header=(0))
        TAS['gene_num']=TAS['gene'].apply(lambda x: len(x.split(',')))
        TAS.to_csv(output[0], sep='\t', index=False)


"""
explode "gene" column
"""

rule explode_gene:
    input:
        "{tumor}.CNVKIT/{tumor}.call.num_genes.cns"
    output:
        ALL_GENES="{tumor}.CNVKIT/{tumor}.call.genes.tsv"
    shell:
        """
        awk '{{ split($4,a,","); \
        for (i in a) print $1"\t"$2"\t"$3"\t"$5"\t"$6"\t"$7"\t"$8"\t"$10"\t"a[i]"\t"$1"_"$2"_"$3; }}' \
        {input} > {output.ALL_GENES}

        """


"""
collapse according to gene name (remove the target suffix)
"""

rule collapse_gene:
    input:
        TAS_data="{tumor}.CNVKIT/{tumor}.call.genes.tsv"
    output:
        ALL_GENES="{tumor}.CNVKIT/{tumor}.call.genes.collapse.tsv"
    run:
        import pandas as pd
        TAS=pd.read_csv(input.TAS_data, sep='\t', header=(0))
        TAS['gene'] = TAS['gene'].apply(lambda x: x.split('_')[0])
        TAS_dd = TAS.drop_duplicates()
        TAS_dd.to_csv(output[0], sep='\t', index=False)


"""
select only lines containg certain gene
"""

rule get_gene:
    input:
        "{tumor}.CNVKIT/{tumor}.call.genes.collapse.tsv"
    output:
        GENE="{tumor}.CNVKIT/{tumor}.call.gene.tsv"
    shell:
        """
        awk 'NR==1 ||\
        $9 ~ /gene/ {{ print $1"\t"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7"\t"$8"\t"$9"\t"$10}}'  \
        {input} > {output.GENE}
        """


"""
Identify targeted genes with copy number gain or loss (above or below a threshold)
"""

rule genemetrics:
    input:
        CNS="{tumor}.CNVKIT/{tumor}.cns",
        CNR="{tumor}.CNVKIT/{tumor}.cnr"
    output:
        GAINLOSS="{tumor}.CNVKIT/{tumor}.gene.gainloss.txt"
    shell:
        """
        cnvkit.py genemetrics -y {input.CNR} -s {input.CNS} > {output.GAINLOSS}
        """




"""
compare cnv and fish data taking into account FISH gene abosolute value and cn
"""

"""
rule compare_cnvkit_fish:
    input:
        TAS_data="{tumor}.CNVKIT/{tumor}.call.gene.tsv"
    output:
        "{tumor}.CNVKIT/{tumor}.call.gene.fish_GAIN.tsv"
    params:
        FISH=fish_info
    run:

        TAS=pd.read_csv(input.TAS_data, sep='\t', header=(0))
        TAS['id'] = wildcards.tumor
        merged_inner = pd.merge(left=TAS, right=params.FISH, left_on='id', right_on='Tumor_Sample_Barcode')
        conditions = [(pd.to_numeric(merged_inner['cn']) > 2) & (pd.to_numeric(merged_inner['NewMet']) >= 4)]
        choices = ['TRUE']
        merged_inner['MATCH_GAIN'] = np.select(conditions, choices, default='FALSE')
        merged_inner.to_csv(output[0], sep='\t', index=False)
"""



"""
compare cnv and fish data taking into account FISH gene/CEN7 ratio and cn
"""


"""
compare cnv and fish data
"""

rule compare_cnvkit_fish:
    input:
        TAS_data="{tumor}.CNVKIT/{tumor}.call.gene.tsv"
    output:
        "{tumor}.CNVKIT/{tumor}.call.gene.fish_GAIN.tsv"
    params:
        FISH=fish_info
    run:

        TAS=pd.read_csv(input.TAS_data, sep='\t', header=(0))
        TAS['id'] = wildcards.tumor
        merged_inner = pd.merge(left=TAS, right=params.FISH, left_on='id', right_on='Tumor_Sample_Barcode')

        mask = (merged_inner['CEN7'] != "UNK")
        z_valid = merged_inner[mask]
        conditions = [(pd.to_numeric(z_valid['cn']) > 2) & (pd.to_numeric(z_valid['RATIO_gene_CEN7']) >= 1.8)]
        choices = ['TRUE']
        merged_inner['MATCH_GAIN'] = pd.Series(np.select(conditions, choices, default='FALSE'))
        merged_inner.to_csv(output[0], sep='\t', index=False)



"""
compare cnv and fish data
"""
"""
rule compare_cnvkit_fish_l:
    input:
        TAS_data="{tumor}.CNVKIT/{tumor}.call.gene.fish_GAIN.tsv"
    output:
        "{tumor}.CNVKIT/{tumor}.call.gene.fish_GL.tsv"
    params:
        FISH=fish_info
    run:
        #TAS=pd.read_csv(input.TAS_data, sep='\t', header=(0))
        #TAS['id'] = wildcards.tumor
        #merged_inner = pd.merge(left=TAS, right=params.FISH, left_on='id', right_on='Tumor_Sample_Barcode')
        #print(merged_inner.head())
        merged_inner=input.TAS_data
        print(merged_inner.head())
        mask = (merged_inner['CEN7'] != "UNK")
        z_valid = merged_inner[mask]
        conditions = [(pd.to_numeric(z_valid['cn']) < 2) & (pd.to_numeric(z_valid['RATIO_gene_CEN7']) < 1.8)]
        choices = ['TRUE']
        merged_inner['MATCH_LOSS'] = np.select(conditions, choices, default='FALSE')
        merged_inner.to_csv(output[0], sep='\t', index=False)


"""



"""
merge data
"""

rule summary:
    input:
        expand(["{tumor}.CNVKIT/{tumor}.call.gene.fish_GAIN.tsv"], tumor=TUMOR.split(' '))
    output:
        "gene_summary.tsv"
    run:
        frames=[]
        for file in input:
            frames.append(pd.read_csv(file, sep='\t', header=(0), engine='python'))
        result = pd.concat(frames)
        result['length'] = result['end'] - result['start']
        result['RATIO_gene_CEN7'] = result['RATIO_gene_CEN7'].astype(str)
        result.to_csv(output[0], sep='\t', index=False)




"""
merge chr 7 info of different samples
"""

rule summary_chr7:
    input:
        expand(["{tumor}.CNVKIT/{tumor}_chr7.cnr"], tumor=TUMOR.split(' '))
    output:
        "chr7_summary_new.tsv"
    run:
        frames=[]
        for file in input:
            frames.append(pd.read_csv(file, sep='\t', header=(0), engine='python'))
        result = pd.concat(frames)
        print(result.head())
        result['length_chr7'] = result['end_chr7'] - result['start_chr7']
        result.to_csv(output[0], sep='\t', index=False)





"""
compare gene and chr7 data
"""

rule compare_cnvkit_chr:
    input:
        CHR7="chr7_summary_new.tsv",
        gene="gene_summary.tsv"
    output:
        "gene_summary_new_chr7.tsv"
    run:
        TAS=pd.read_csv(input.gene, sep='\t', header=(0))
        TASCR=pd.read_csv(input.CHR7, sep='\t', header=(0))
        merged_inner = pd.merge(left=TAS, right=TASCR, left_on='id', right_on='id')
        merged_inner["log2_gene/log2_chr7"]=merged_inner.log2.div(merged_inner.log2_chr7, axis='index')
        merged_inner["depth_gene/depth_chr7"]=merged_inner.depth.div(merged_inner.depth_chr7, axis='index')
        merged_inner["depth_gene/depth_chr7"] = pd.to_numeric(round(merged_inner["depth_gene/depth_chr7"].apply(lambda x: float(x)),3))
        merged_inner["log2_gene/log2_chr7"] = pd.to_numeric(round(merged_inner["log2_gene/log2_chr7"].apply(lambda x: float(x)),3))
        merged_inner["depth_chr7"] = pd.to_numeric(round(merged_inner["depth"].apply(lambda x: float(x)),3))
        merged_inner.to_csv(output[0], sep='\t', index=False)
        #merged_inner.to_csv(output[0], index=False)



"""
PLOTS
"""


rule cnvkit_scatter_region:
    input:
        CNR="{tumor}.CNVKIT/{tumor}.cnr",
        CNS="{tumor}.CNVKIT/{tumor}.call.cns"
    output:
        "CNVKIT_PLOTS/{tumor}-scatter-region.pdf"
    shell:
        "cnvkit.py scatter {input.CNR} -s {input.CNS} -c chr7 -g gene,EGFR,BRAF,EZH2,RAC1,HDAC9,CDK6 --y-max 5 --y-min -3 -o {output}"



rule cnvkit_heatmap:
    input:
        expand(["{tumor}.CNVKIT/{tumor}.cns"], tumor=TUMOR.split(' '))
    output:
        "CNVKIT_PLOTS/all_heatmap.pdf"
    shell:
        "cnvkit.py heatmap {input} -o {output}"

:%s/gene/gene/g



