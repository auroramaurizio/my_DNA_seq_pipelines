import sys
import logging
from snakemake.io import glob_wildcards, expand
import glob,os
import pathlib
import csv
import pandas as pd
import numpy as np


path = "logs_slurm"
try:
    os.mkdir(path)
except OSError:
    print ("Creation of the directory %s failed" % path)
else:
    print ("Successfully created the directory %s " % path)



DATADIR_SHORT = "/beegfs/scratch/demux/"
runs_set = set(["220128_A00626_0403_BHL7GGDRXY"])
runs = ' '.join(map(str, runs_set))


project = set(["620_WES"])
proj = ' '.join(map(str, project))


DATADIR="/beegfs/scratch/ric.cosr/ric.cosr/runs/220128_A00626_0403_BHL7GGDRXY/620_WES"


SAMPLE_LIST_DIR = os.listdir(DATADIR)


SUFF = []


for file in SAMPLE_LIST_DIR:
    A = file
    SUFF.append(A)


SUFF=set(SUFF)

print(SUFF)


SUFFIX = ' '.join(map(str, SUFF))
print("SUFFIX", SUFFIX)

def get_rgidfromrun(run):
    return str(run.split("_")[3])



rule all:
    input:
      expand(["qc/{run}/{prj}/{pref}"], pref=SUFFIX.split(' '), prj=proj, run=runs.split(' ')),
      expand(["qualimap/{pref}"], pref=SUFFIX.split(' ')),
      expand(["OxoG/{pref}_OxoG_metrics.txt"], pref=SUFFIX.split(' ')),
      expand(["hsmetrics/{pref}_hs_metrics.txt"], pref=SUFFIX.split(' '))



rule mergeFastq:
    output:
        R1 = "MERGED_FQ/{run}/{prj}/{pref}_R1.fastq.gz",
        R2 = "MERGED_FQ/{run}/{prj}/{pref}_R2.fastq.gz"
    resources: time_min = 500, mem_mb=2500, cpus = 2
    shell: """
        mkdir -p MERGED_FQ
            cat {DATADIR_SHORT}/{wildcards.run}/{wildcards.prj}/{wildcards.pref}/{wildcards.pref}_S*_R1_001.fastq.gz > {output.R1}
            cat {DATADIR_SHORT}/{wildcards.run}/{wildcards.prj}/{wildcards.pref}/{wildcards.pref}_S*_R2_001.fastq.gz > {output.R2}
        """


rule fix_tiles:
    input:
        R1="MERGED_FQ/{run}/{prj}/{pref}_R1.fastq.gz",
        R2="MERGED_FQ/{run}/{prj}/{pref}_R2.fastq.gz",
        adapters = "adapters-pe.fa"
    output:
        R1="tiles_hh/{run}/{prj}/{pref}_R1.fastq.gz",
        R2="tiles_hh/{run}/{prj}/{pref}_R2.fastq.gz"
    threads: 12
    resources: time_min=50000, mem_mb=64000, cpus=32
    shell:"""
        mkdir -p tiles_hh
        filterbytile.sh in={input.R1} in2={input.R2} out={output.R1} out2={output.R2}  ud=0.75 qd=1 ed=1 ua=.5 qa=.5 ea=.5
       """




rule trimming:
    input:
        R1="tiles_hh/{run}/{prj}/{pref}_R1.fastq.gz",
        R2="tiles_hh/{run}/{prj}/{pref}_R2.fastq.gz",
        adapters = "adapters-pe.fa"
    output:
        R1="trimmed_hh/{run}/{prj}/{pref}_R1.fastq.gz",
        R2="trimmed_hh/{run}/{prj}/{pref}_R2.fastq.gz"
    log:
        main="trimmed_hh/{run}/{prj}/{pref}_trim.log",
        out="trimmed_hh/{run}/{prj}/{pref}_trimout.log"
    threads: 12
    resources: time_min=50000, mem_mb=64000, cpus=32
    shell:"""
        mkdir -p trimmed_hhh
        bbduk.sh -Xmx24g in={input.R1} in2={input.R2} out={output.R1} out2={output.R2} ref={input.adapters} k=23 mink=11 rcomp=t ktrim=f kmask=X qtrim=rl trimq=5 forcetrimleft=5 forcetrimright2=0  overwrite=true stats={log.main}  2> "{log.out}"
       """





rule fastqc_tiles:
    input:
        R1 = "trimmed_hh/{run}/{prj}/{pref}_R1.fastq.gz",
        R2 = "trimmed_hh/{run}/{prj}/{pref}_R2.fastq.gz"
    output:
        directory("qc_tiles_hh/{run}/{prj}/{pref}")
    params: ""
    log:
        "logs/fastqc/{run}_{prj}_{pref}.log"
    threads: 12
    resources: time_min = 50000, mem_mb=25000, cpus = 32
    shell:"""
        mkdir -p "qc_tiles_hh/{wildcards.run}/{wildcards.prj}/{wildcards.pref}"
        fastqc -o {output} {input.R1} {input.R2}
        """






# merge in unique folder sample fastqs from different runs
#rule all:
#    input:
#      expand(["MERGED/{pref}_R1.fastq.gz"], pref=SUFFIX.split(' ')),
#      expand(["MERGED/{pref}_R2.fastq.gz"], pref=SUFFIX.split(' '))




#rule merge_R1:
#    output:
#        "MERGED/{pref}_R1.fastq.gz"
#    resources: time_min = 5000, mem_mb=25000, cpus = 32
#    threads: 32
#    shell:"""
#        array=()
#        array=$(find MERGED_FQ -name "{wildcards.pref}_R1.fastq.gz")
#        echo $array
#
#        cat $array > {output}
#        """



#rule merge_R2:
#    output:
#        "MERGED/{pref}_R2.fastq.gz"
#    resources: time_min = 5000, mem_mb=25000, cpus = 32
#    threads: 32
#    shell:"""
#        array=()
#        array=$(find MERGED_FQ -name "{wildcards.pref}_R2.fastq.gz")
#        echo $array
#
#        cat $array > {output}
#        """





rule fastqc:
    input:
        R1 = "trimmed/{run}/{prj}/{pref}_R1.fastq.gz",
        R2 = "trimmed/{run}/{prj}/{pref}_R2.fastq.gz"
    output:
        directory("qc/{run}/{prj}/{pref}")
    params: ""
    log:
        "logs/fastqc/{run}_{prj}_{pref}.log"
    threads: 12
    resources: time_min = 50000, mem_mb=25000, cpus = 18
    shell:"""
            mkdir -p "qc/{wildcards.run}/{wildcards.prj}/{wildcards.pref}"
            fastqc -o {output} {input.R1} {input.R2}
        """



rule trimming:
    input:
        R1="MERGED_FQ/{run}/{prj}/{pref}_R1.fastq.gz",
        R2="MERGED_FQ/{run}/{prj}/{pref}_R2.fastq.gz",
        adapters = "adapters-pe.fa"
    output:
        R1="trimmed/{run}/{prj}/{pref}_R1.fastq.gz",
        R2="trimmed/{run}/{prj}/{pref}_R2.fastq.gz"
    log: 
        main="trimmed/{run}/{prj}/{pref}_trim.log",
        out="trimmed/{run}/{prj}/{pref}_trimout.log"
    threads: 12
    resources: time_min=50000, mem_mb=64000, cpus=32
    shell:"""
        mkdir -p trimmed
        bbduk.sh -Xmx24g in={input.R1} in2={input.R2} out={output.R1} out2={output.R2} ref={input.adapters} k=23 mink=11 rcomp=t ktrim=f kmask=X qtrim=rl trimq=5 forcetrimleft=0 forcetrimright2=0  overwrite=true stats={log.main}  2> "{log.out}"

       """





rule map:
    input:
        R1="trimmed_hh/{run}/{prj}/{pref}_R1.fastq.gz",
        R2="trimmed_hh/{run}/{prj}/{pref}_R2.fastq.gz",
        reference="/beegfs/datasets/genomes/hg38/GATK_bundle_new/v0/Homo_sapiens_assembly38.fasta"
    params:
        id = lambda wildcards: get_rgidfromrun(f"{wildcards.run}"),
        pu=lambda wildcards: f"{wildcards.run}.{wildcards.pref}",
        sm=lambda wildcards: f"{wildcards.pref}",
        pl="NextSeq500"
        #lb = lambda wildcards:get_rgidfromrun(f"{wildcards.run}").f"{wildcards.pref}"
    output:
        "mapped/{run}/{prj}/{pref}.bam"
    threads: 32
    resources: time_min=50000, mem_mb=25000, cpus=32
    shell:"""

       bwa mem -t 72 -M -R '@RG\\tID:{params.id}.{params.sm}\\tPL:{params.pl}\\tPU:{params.pu}\\tSM:{params.sm}\\tLB:{params.id}.{params.sm}\\tCN:COSR\\tSO:unsorted' {input.reference} {input.R1} {input.R2} | samtools view -Sb > {output}

       """


rule samtools_sort_map:
    input:
        "mapped/{run}/{prj}/{pref}.bam"
    output:
        "sorted/{run}/{prj}/{pref}.bam"
    resources: time_min = 5000, mem_mb=25000, cpus = 18
    shell:"""
        mkdir -p sorted
        samtools sort {input} -o {output}
        """



#rule sort_map:
#    input:
#        "mapped/{run}/{prj}/{pref}.bam"
#    output:
#        "sorted/{run}/{prj}/{pref}.bam"
#    resources: time_min = 5000, mem_mb=25000, cpus = 32
#    threads: 32
#    shell:"""
#        mkdir -p sorted
#        sambamba sort -t {threads} {input} -o {output}
#        """

rule samtools_merge:
    input:
        expand("sorted/{run}/{prj}/{{pref}}.bam",run=runs.split(' '), prj=proj, pref=SUFFIX.split(' '))
    output:
        "merged_bam/{pref}.bam"
    resources: time_min = 5000, mem_mb=25000, cpus = 18
    threads: 18
    shell:"""
        mkdir -p merged_bam
        samtools merge -@ {threads} {output} {input}
        """

rule rmdup_only_marked:
    input:
        "merged_bam/{pref}.bam"
    output:
        reads = "markdup/{pref}_markdup.bam",
        metrics = "markdup/{pref}_markdup_metrics.log"
    resources: time_min=5000, mem_mb=2500, cpus=32
    shell:"""
       mkdir -p markdup
       picard MarkDuplicates REMOVE_DUPLICATES=false\
       I={input} \
       O={output.reads} \
       M={output.metrics}
       """


rule samtools_sort_marked:
    input:
        "markdup/{pref}_markdup.bam"
    output:
        "sorted/{pref}_markdup.bam"
    resources: time_min = 5000, mem_mb=25000, cpus = 32
    shell:"""
        mkdir -p sorted
        samtools sort {input} -o {output}
        """


rule samtools_index_only_marked:
    input:
        BAM = "sorted/{pref}_markdup.bam"
    output:
        "sorted/{pref}_markdup.bam.bai"
    resources: time_min = 500, mem_mb=2500, cpus = 16
    shell:"""
        samtools index {input.BAM}
        touch {output}
        """



rule clipOverlap:
    input:
        BAM = "sorted/{pref}_markdup.bam"
    output:
        "clipOverlap/{pref}_markdup.bam"
    resources: time_min = 500, mem_mb=2500, cpus = 16
    shell:"""
        mkdir -p clipOverlap
        bam clipOverlap --in {input.BAM} --out {output} --stats --unmapped --storeOrig
        touch {output}
        """



rule clipOverlap_index:
    input:
        BAM = "clipOverlap/{pref}_markdup.bam"
    output:
        "clipOverlap/{pref}_markdup.bam.bai"
    resources: time_min = 500, mem_mb=2500, cpus = 16
    shell:"""
        samtools index {input.BAM}
        touch {output}
        """



         

#as an alternative to samtools you can use sambamba

#rule markdup:
#    input:
#        "merged_bam/{pref}.bam"
#    output:
#        reads = "markdup/{pref}_markdup.bam",
#        metrics = "markdup/{pref}_markdup_metrics.log"
#    resources: time_min=5000, mem_mb=25000, cpus=32
#    threads: 32
#    shell: """
#       mkdir -p markdup
#       sambamba markdup -t {threads} {input} {output.reads} >  {output.metrics} 2>&1
#       """

#rule samtools_sort_marked:
#    input:
#        "markdup/{pref}_markdup.bam"
#    output:
#        "sorted/{pref}_markdup.bam"
#    resources: time_min = 5000, mem_mb=25000, cpus = 32
#    threads: 32
#    shell:"""
#        mkdir -p sorted
#        sambamba sort -t {threads} {input} -o {output}
#        """


#rule samtools_index_only_marked:
#    input:
#        BAM = "sorted/{pref}_markdup.bam"
#    output:
#        "sorted/{pref}_markdup.bam.bai"
#    resources: time_min = 500, mem_mb=2500, cpus = 16
#    threads: 16
#    shell:"""
#        sambamba index -t {threads} {input.BAM}
#        touch {output}
#        """

#Collect metrics to assess oxidative artifacts. useful for FFPE samples
rule OxoG:
    input:
        "sorted/{pref}_markdup.bam"
    params:
        int="/beegfs/datasets/buffer/ric.cosr/wes/Twist_Exome_RefSeq_targets_hg38.interval_list",
        reference="/beegfs/datasets/genomes/hg38/GATK_bundle_new/v0/Homo_sapiens_assembly38.fasta"
    output:
        "OxoG/{pref}_OxoG_metrics.txt"
    resources: time_min = 50000, mem_mb=50000, cpus = 20
    threads: 20
    shell:"""
        mkdir -p OxoG
        picard CollectOxoGMetrics\
        I={input} \
        O={output} \
        R={params.reference} \
        INTERVALS={params.int}
        """


#target bed file must contain at least 6 fields

rule qualimap:
    input:
        "sorted/{pref}_markdup.bam"
    params:
        bed="Twist_Exome_RefSeq_targets_hg38.6fields.txt"
    output:
        directory("qualimap/{pref}")
    resources: time_min = 50000, mem_mb=50000, cpus = 20
    threads: 20
    shell:"""
        mkdir -p "qualimap/{wildcards.pref}"
        qualimap --java-mem-size=50000M bamqc -nt {threads} -c -bam {input} -outdir {output} --feature-file {params.bed}
        """


#rule interval_list:
#    input:
#      #bed = "/beegfs/scratch/ric.cosr/ric.cosr/210724_A00626_0314_BH3CYVDMXY/Twist_Exome_Target_hg38.bed"
#      bed = "/beegfs/datasets/buffer/ric.cosr/wes/Twist_Exome_RefSeq_targets_hg38.bed"
#    output:
#      #"/beegfs/scratch/ric.cosr/ric.cosr/210724_A00626_0314_BH3CYVDMXY/Twist_Exome_Target_hg38.interval_list"
#      "/beegfs/datasets/buffer/ric.cosr/wes/Twist_Exome_RefSeq_targets_hg38.interval_list"
#    resources: time_min = 50000, mem_mb=50000, cpus = 32
#    shell:"""
#      picard BedToIntervalList \
#      I={input.bed} \
#      O={output} \
#      SD="/beegfs/datasets/genomes/hg38/GATK_bundle_new/v0/Homo_sapiens_assembly38.dict"
#      """

rule HsMetrics:
    input:
      BAM = "sorted/{pref}_markdup.bam"
    output:
      HsMetrics = "hsmetrics/{pref}_hs_metrics.txt"
    params:
      reference = "/beegfs/datasets/genomes/hg38/GATK_bundle_new/v0/Homo_sapiens_assembly38.fasta",
      baits = "/beegfs/datasets/buffer/ric.cosr/wes/Twist_Exome_RefSeq_targets_hg38.interval_list"
    resources: time_min = 50000, mem_mb=50000, cpus = 32
    shell:"""
    bash -c '
    . $HOME/.bashrc
    conda activate pypette-dna-wes   
    mkdir -p hsmetrics
    picard CollectHsMetrics \
      I={input.BAM} \
      O={output.HsMetrics} \
      R={params.reference} \
      BAIT_INTERVALS={params.baits} \
      TARGET_INTERVALS={params.baits}
    conda deactivate'
      """



rule MQC:
    params:
        qualimap = "qualimap/",
        QC = "qc/",
        PICARD = "markdup/",
        HsMETRICS = "hsmetrics",
    output: "MQC.done"
    resources: time_min = 5000, mem_mb=12800, cpus = 16
    shell:"""
       multiqc {params.QC}  {params.qualimap} {params.HsMETRICS} {params.PICARD}
       touch {output}
       """



